-- docker build
```
docker run -itd -v /data/gitlab/crh/apache-ambari-2.5.1-src:/tmp/ambari -v /data/software/maven/repository:/root/.m2/repository -v ~/.npm:/root/.npm -v ~/.cache:/root/.cache ambari/build /bin/bash  
```


-- CRH 
```

bash -c "clear && docker exec -it lucid_gates sh"

mvn -B -X clean package rpm:rpm -DskipTests -DnewVersion=2.5.1.0.0 -Dstack.distribution=CRH -P pluggable-stack-definition -Dpython.ver="python >= 2.6" -Preplaceurl -Drat.skip -X

```

-- HDP 
```
bash -c "clear && docker exec -it romantic_mirzakhani sh"

mvn -B -X clean install package rpm:rpm -DskipTests -Dpython.ver="python >= 2.6" -Preplaceurl -Drat.skip -X
```

-- BIGTOP
# Setup a Jenkins master
```
# create jenkins user on host machine with uid=1000 to map the jenkins uid inside jenkins image
sudo adduser jenkins -u 1000
sudo yum install -y docker git
sudo su - jenkins -c "git config --global user.email \"jenkins@bigtop.apache.org\""
sudo su - jenkins -c "git config --global user.name \"jenkins\""
sudo usermod -a -G root jenkins
sudo service docker start
sudo su - jenkins -c "docker run -d --name jenkins-master -p 80:8080 -v `pwd`:/var/jenkins_home jenkins"
sudo su - jenkins -c "docker run -u jenkins -d --name jenkins-master -p 8888:8080 -v /data:/var/jenkins_home jenkins"
```

# set build bigtop slave
```
docker run --rm -v /home/jenkins/workspace/Bigtop-1.0.0-rpm/BUILD_ENVIRONMENTS/centos-6/label/docker-slave-06:/ws bigtop/slaves:centos-6 bash -c '. /etc/profile.d/bigtop.sh; cd /ws ; A=yum ; type -p dpkg && A=apt ; ./gradlew allclean; ./gradlew $A'

docker run -itd -v /data/bigtop-1.2.1:/ws --workdir /ws -v /data/software/repository:/root/.m2/repository -v ~/.npm:/root/.npm -v ~/.cache:/root/.cache bigtop/slaves:1.2.1-centos-7 /bin/bash 
```

# Jenkins install for 
```
 yum install java-1.8.0-openjdk
 
```

ambari编译”Ambari Web“报错：

[ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.4:install-node-and-yarn (install node and yarn) on project ambari-web: The plugin com.github.eirslett:frontend-maven-plugin:1.4 requires Maven version 3.1.0 -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.4:install-node-and-yarn (install node and yarn) on project ambari-web: The plugin com.github.eirslett:frontend-maven-plugin:1.4 requires Maven version 3.1.0
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:170)

- ambari-server编译失败：

[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (enforce-maven) on project ambari-server: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (enforce-maven) on project ambari-server: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed.

mvn -B -X clean install package rpm:rpm -DskipTests -Denforcer.skip=true -Dpython.ver="python >= 2.6" -Preplaceurl

原因如下：
	<plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-enforcer-plugin</artifactId>
        <executions>
          <execution>
            <id>enforce-maven</id>
            <phase>validate</phase>
            <goals>
              <goal>enforce</goal>
            </goals>
            <configuration>
              <rules>
                <requireMavenVersion>
                  <version>[3.3.9,)</version>
                </requireMavenVersion>
              </rules>
            </configuration>
          </execution>
        </executions>
      </plugin>


[DEBUG] Cannot find ArtifactResolver with hint: project-cache-aware
org.codehaus.plexus.component.repository.exception.ComponentLookupException: java.util.NoSuchElementException
      role: org.apache.maven.artifact.resolver.ArtifactResolver
  roleHint: project-cache-aware


iptables -A PREROUTING -t nat -i enp9s0 -p tcp --dport 9090 -j REDIRECT --to-port 9090

“Crawler_and_Share共享 data 平台” -> GitHub: https://github.com/f496328mm/Crawler_and_Share ​​​


问下各位大神 spark on yarn accepted状态是指 资源不足才出现的吧 但是我有个任务申请了10个executor 刚开始起了三个 隔了半小时才起完十个 这种情况是不是说任务提交的时候是够的 但是启动过程的时候却不够了



用spark跑过 50TB左右的数据没 ？

admaster这边 以前用MR跑50-60TB的数据  一天都跑不出来 400+节点 128G内存 ？

要起10万个map  5万个reduce ？



请问关于hbase入库的这块，我直接使用kafka的消费api从kafka上读取消息。然后往hbase上写。现在发现写入的性能并不是很理想。还有在入库的阶段，hbasea上的节点regionServer经常由于oom导致宕机~这个应该从哪些方面思考呢?


oom需要排查？什么原因导致的？阻塞了？

刚开始，我设计表没作预分区，热点导致，然后简单作了几个分区后，相对好了一些

通过Impala去关联查询Hbase时，性能不高?

hbase问题就是热点问题以及split?

嗯，3个节点。分了预分了6个。hash字段让它随机。hbase如何当实时数据库使用的？！只是为了解决储存吗？

用spark跑过 50TB左右的数据没？

vmware：https://www.yeboyzq.com/xvnihua/850.html





